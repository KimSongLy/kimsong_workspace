# -*- coding: utf-8 -*-
"""Python Training - 001.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1N0NunxsW1z0edGq2IDU_1Dt5zosmCx7e
"""

import pandas as pd
import numpy as np

from sklearn import preprocessing

#visualizations
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.ticker import NullFormatter
import matplotlib.ticker as ticker

df = pd.read_csv('loan_train.csv')

df.head()

df.shape

# date format Correction
df['due_date'] = pd.to_datetime(df['due_date'])
df['effective_date'] = pd.to_datetime(df['effective_date'])
df.head()

# data visualization
bins = np.linspace(df.Principal.min(), df.Principal.max(), 10)
g = sns.FacetGrid(df, col='Gender', hue='loan_status')
g.map(plt.hist, 'Principal', bins=bins)
#g.axes[-1].legend

# preprocessing phase
df['dayofweek'] = df['effective_date'].dt.dayofweek
df['weekend'] = df['dayofweek'].apply(lambda x:1 if ('x > 3') else 0)

df.head()

df['Gender'].replace(to_replace=['male','female'], value=[0,1], inplace=True)
df.head()

# on-hot enconding
feature = df[['Principal', 'terms', 'age', 'Gender', 'weekend']]
feature = pd.concat([feature, pd.get_dummies(df['education'])], axis=1)
feature.head()

feature.drop(['Master or Above'], axis=1)

feature.head()

X = feature

y = df['loan_status'].values
print(y[0:5])

# Normalize
X = preprocessing.StandardScaler().fit(X).transform(X)
print(X[0:5])

# split dataset into training and test set
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)
x_train.shape

y_train.shape

x_test.shape

y_test.shape

# SVM model
from sklearn import svm

svm_model = svm.SVC(kernel='rbf')

svm_model.fit(x_train, y_train)

y_hat = svm_model.predict(x_test)

y_hat

# Logistic regression
from sklearn.linear_model import LogisticRegression
LR = LogisticRegression(C=0.01, solver='liblinear').fit(x_train, (y_train))

y_hat_lr = LR.predict(x_test)

# Evaluation 
from sklearn.metrics import jaccard_score
from sklearn.metrics import f1_score
from sklearn.metrics import log_loss
